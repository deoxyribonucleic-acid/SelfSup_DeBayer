{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch, torchvision\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from train_new import UNet, get_SIDD_validation, calculate_psnr, calculate_ssim, BayerPatternShifter\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from scipy.io import loadmat\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def get_SIDD_validation(dataset_dir):\n",
    "    val_data_dict = loadmat(\n",
    "        os.path.join(dataset_dir, \"ValidationNoisyBlocksRaw.mat\"))\n",
    "    val_data_noisy = val_data_dict['ValidationNoisyBlocksRaw']\n",
    "    val_data_dict = loadmat(\n",
    "        os.path.join(dataset_dir, 'ValidationGtBlocksSrgb.mat'))\n",
    "    val_data_gt = val_data_dict['ValidationGtBlocksSrgb']\n",
    "    # print(val_data_gt.shape)\n",
    "    num_img, num_block, _, _, _ = val_data_gt.shape\n",
    "    return num_img, num_block, val_data_noisy, val_data_gt\n",
    "\n",
    "\n",
    "def test(model_path, data_dir, out_dir):\n",
    "    model = UNet(in_channels=4, out_channels=3, wf=48).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "\n",
    "    num_img, num_block, val_noisy, val_gt = get_SIDD_validation(data_dir)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    psnr_list, ssim_list = [], []\n",
    "\n",
    "    for idx in tqdm(range(num_img), desc=\"Testing\", unit=\"image\"):\n",
    "        for idy in tqdm(range(num_block), desc=\"Processing blocks\", unit=\"block\"):\n",
    "            gt = val_gt[idx, idy] / 255.0  # [H, W, 3]\n",
    "            # print(gt.shape)\n",
    "            noisy = val_noisy[idx, idy][:, :, np.newaxis]  # [H, W, 1]\n",
    "\n",
    "            transformer = transforms.Compose([transforms.ToTensor()])\n",
    "            noisy_tensor = transformer(noisy).unsqueeze(0).to(device)\n",
    "            noisy_tensor = BayerPatternShifter.bayer_1ch_to_4ch(noisy_tensor)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                pred_rgb = model(noisy_tensor)\n",
    "\n",
    "            pred_rgb = pred_rgb.permute(0, 2, 3, 1).cpu().clamp(0, 1).numpy().squeeze(0)\n",
    "            pred255 = np.clip(pred_rgb * 255.0 + 0.5, 0, 255).astype(np.uint8)\n",
    "\n",
    "            psnr = calculate_psnr(gt.astype(np.float32), pred_rgb.astype(np.float32), 1.0)\n",
    "            ssim = calculate_ssim(gt * 255.0, pred_rgb * 255.0)\n",
    "            psnr_list.append(psnr)\n",
    "            ssim_list.append(ssim)\n",
    "\n",
    "            save_path = os.path.join(out_dir, f\"val_{idx:03d}_{idy:03d}.png\")\n",
    "            Image.fromarray(pred255).save(save_path)\n",
    "\n",
    "    print(f\"Average PSNR: {np.mean(psnr_list):.4f}, SSIM: {np.mean(ssim_list):.4f}\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 512, 768])\n"
     ]
    },
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'B' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 85\u001b[0m\n\u001b[1;32m     82\u001b[0m      \u001b[38;5;66;03m# plot_channel(interp_8bit)\u001b[39;00m\n\u001b[1;32m     83\u001b[0m      \u001b[38;5;28;01mreturn\u001b[39;00m interp_8bit\n\u001b[0;32m---> 85\u001b[0m simple_demosaic \u001b[38;5;241m=\u001b[39m \u001b[43minterp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbayer_f_3ch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28mprint\u001b[39m(simple_demosaic\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     88\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[41], line 44\u001b[0m, in \u001b[0;36minterp\u001b[0;34m(bayer)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minterp\u001b[39m(bayer):\n\u001b[1;32m     42\u001b[0m  \n\u001b[1;32m     43\u001b[0m      \u001b[38;5;66;03m# Interpolate blue, last col and first row is all 0\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m      B \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mpad(\u001b[43mB\u001b[49m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     45\u001b[0m      B[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m (np\u001b[38;5;241m.\u001b[39marray(B[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m2\u001b[39m]) \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39marray(B[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m::\u001b[38;5;241m2\u001b[39m])) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;66;03m# row\u001b[39;00m\n\u001b[1;32m     46\u001b[0m      B[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m B[\u001b[38;5;241m2\u001b[39m::\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;66;03m# last col\u001b[39;00m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'B' referenced before assignment"
     ]
    }
   ],
   "source": [
    "# parser = argparse.ArgumentParser()\n",
    "# parser.add_argument('--checkpoint', type=str, required=True, help='Path to trained model (.pth)')\n",
    "# parser.add_argument('--test_dir', type=str, required=True, help='Path to validation data folder')\n",
    "# parser.add_argument('--out_dir', type=str, default='./test_results', help='Directory to save predictions')\n",
    "# args = parser.parse_args()\n",
    "\n",
    "# test(args.checkpoint, args.test_dir, args.out_dir)\n",
    "test_im = Image.open('./data/validation/kodim01.png')\n",
    "shifter = BayerPatternShifter()\n",
    "test_im = test_im.convert('RGB')\n",
    "test_im = torchvision.transforms.ToTensor()(test_im).to(device)\n",
    "# print(test_im.shape)\n",
    "bayer_f_4ch = shifter.remosaic(test_im, 'RGGB', out_channel=4)\n",
    "print(bayer_f_4ch.shape)  # [1, 4, H, W]\n",
    "# merge 2 G channels of bayer_f\n",
    "bayer_f_3ch = bayer_f_4ch.clone()\n",
    "bayer_f_3ch[1, :, :] = (bayer_f_4ch[1, :, :] + bayer_f_4ch[2, :, :])\n",
    "bayer_f_3ch[2, :, :] = bayer_f_4ch[3, :, :]\n",
    "bayer_f_3ch = bayer_f_3ch[[0, 1, 2], :, :]  # [1, 3, H, W]\n",
    "\n",
    "bayer_f_1ch = shifter.remosaic(test_im, 'RGGB', out_channel=1)\n",
    "\n",
    "def bilinear_demosaic_rggb(bayer):\n",
    "    # bayer: [B, 3, H, W]\n",
    "    print(bayer.shape)\n",
    "\n",
    "    # 获取 R, G, B 通道\n",
    "    R = bayer[:, 0, :, :]  # [B, H, W]\n",
    "    G = bayer[:, 1, :, :]  # [B, H, W]\n",
    "    B_ = bayer[:, 2, :, :]  # [B, H, W]\n",
    "\n",
    "    # 插值空位置\n",
    "    R = F.interpolate(R.unsqueeze(1), scale_factor=1, mode='bilinear', align_corners=False)\n",
    "    G = F.interpolate(G.unsqueeze(1), scale_factor=1, mode='bilinear', align_corners=False)\n",
    "    B_ = F.interpolate(B_.unsqueeze(1), scale_factor=1, mode='bilinear', align_corners=False)\n",
    "\n",
    "    # 拼接成 RGB\n",
    "    rgb = torch.cat([R, G, B_], dim=1)  # [B, 3, H, W]\n",
    "    return rgb\n",
    "\n",
    "\n",
    "\n",
    "simple_demosaic = bilinear_demosaic_rggb(bayer_f_3ch.unsqueeze(0))\n",
    "print(simple_demosaic.shape)\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.imshow(test_im.permute(1, 2, 0).cpu().numpy())\n",
    "plt.title('Original')\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.imshow(bayer_f_3ch.squeeze(0).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title('Bayer Pattern')\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.imshow(simple_demosaic.squeeze(0).permute(1, 2, 0).cpu().numpy())\n",
    "plt.title('Simple Demosaic')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "556",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
